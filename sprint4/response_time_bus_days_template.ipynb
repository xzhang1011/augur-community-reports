{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR Response Time Analysis (Business Days)\n",
    "\n",
    "Learn whether your community is responding to pull requests within\n",
    "a reasonable timeframe by comparing response times to a number of business\n",
    "days threshold / expectation that you set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up database connection and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd \n",
    "import sqlalchemy as s\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import warnings\n",
    "import datetime\n",
    "from pandas.tseries.offsets import BusinessDay\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "with open(\"config.json\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "database_connection_string = 'postgres+psycopg2://{}:{}@{}:{}/{}'.format(config['user'], config['password'], config['host'], config['port'], config['database'])\n",
    "\n",
    "dbschema='augur_data'\n",
    "engine = s.create_engine(\n",
    "    database_connection_string,\n",
    "    connect_args={'options': '-csearch_path={}'.format(dbschema)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Cell - Set Variables and Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the repo_id for the analysis\n",
    "repo_id = 28051\n",
    "\n",
    "# Provide number of business days threshold. This is the number of business days\n",
    "# within which you expect people to respond to PRs. Default is 2 business days.\n",
    "bus_days = 2\n",
    "\n",
    "#specify dates for filtering - a typical default would be one year of data\n",
    "#if the end_date is in the future, the end_date will default to the current_date\n",
    "begin_date = '2020-02-01'\n",
    "end_date = '2021-01-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering and Processing the Data\n",
    "\n",
    "## Getting the data from your Augur database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/virtualenvs/augur-community-reports/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9774d964c0bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m        \"\"\"\n\u001b[1;32m    135\u001b[0m \u001b[0mget_repo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_repo_name_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mrepo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_repo_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtualenvs/augur-community-reports/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/augur-community-reports/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4410\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4411\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4412\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4413\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": [
    "pr_all = pd.DataFrame()\n",
    "\n",
    "pr_query = s.sql.text(f\"\"\"\n",
    "                 SELECT\n",
    "                    repo.repo_id AS repo_id,\n",
    "                    pull_requests.pr_src_id AS pr_src_id,\n",
    "                    repo.repo_name AS repo_name,\n",
    "                    pr_src_author_association,\n",
    "                    repo_groups.rg_name AS repo_group,\n",
    "                    pull_requests.pr_src_state,\n",
    "                    pull_requests.pr_merged_at,\n",
    "                    pull_requests.pr_created_at AS pr_created_at,\n",
    "                    pull_requests.pr_closed_at AS pr_closed_at,\n",
    "                    date_part( 'year', pr_created_at :: DATE ) AS CREATED_YEAR,\n",
    "                    date_part( 'month', pr_created_at :: DATE ) AS CREATED_MONTH,\n",
    "                    date_part( 'year', pr_closed_at :: DATE ) AS CLOSED_YEAR,\n",
    "                    date_part( 'month', pr_closed_at :: DATE ) AS CLOSED_MONTH,\n",
    "                    pr_src_meta_label,\n",
    "                    pr_head_or_base,\n",
    "                    ( EXTRACT ( EPOCH FROM pull_requests.pr_closed_at ) - EXTRACT ( EPOCH FROM pull_requests.pr_created_at ) ) / 3600 AS hours_to_close,\n",
    "                    ( EXTRACT ( EPOCH FROM pull_requests.pr_closed_at ) - EXTRACT ( EPOCH FROM pull_requests.pr_created_at ) ) / 86400 AS days_to_close, \n",
    "                    ( EXTRACT ( EPOCH FROM first_response_time ) - EXTRACT ( EPOCH FROM pull_requests.pr_created_at ) ) / 3600 AS hours_to_first_response,\n",
    "                    ( EXTRACT ( EPOCH FROM first_response_time ) - EXTRACT ( EPOCH FROM pull_requests.pr_created_at ) ) / 86400 AS days_to_first_response, \n",
    "                    ( EXTRACT ( EPOCH FROM last_response_time ) - EXTRACT ( EPOCH FROM pull_requests.pr_created_at ) ) / 3600 AS hours_to_last_response,\n",
    "                    ( EXTRACT ( EPOCH FROM last_response_time ) - EXTRACT ( EPOCH FROM pull_requests.pr_created_at ) ) / 86400 AS days_to_last_response, \n",
    "                    first_response_time,\n",
    "                    last_response_time,\n",
    "                    average_time_between_responses,\n",
    "                    assigned_count,\n",
    "                    review_requested_count,\n",
    "                    labeled_count,\n",
    "                    subscribed_count,\n",
    "                    mentioned_count,\n",
    "                    referenced_count,\n",
    "                    closed_count,\n",
    "                    head_ref_force_pushed_count,\n",
    "                    merged_count,\n",
    "                    milestoned_count,\n",
    "                    unlabeled_count,\n",
    "                    head_ref_deleted_count,\n",
    "                    comment_count,\n",
    "                    lines_added, \n",
    "                    lines_removed,\n",
    "                    commit_count, \n",
    "                    file_count\n",
    "                FROM\n",
    "                repo,\n",
    "                repo_groups,\n",
    "                pull_requests LEFT OUTER JOIN ( \n",
    "                        SELECT pull_requests.pull_request_id,\n",
    "                            MIN(message.msg_timestamp) AS first_response_time,\n",
    "                            COUNT(DISTINCT message.msg_timestamp) AS comment_count,\n",
    "                            MAX(message.msg_timestamp) AS last_response_time,\n",
    "                            (MAX(message.msg_timestamp) - MIN(message.msg_timestamp)) / COUNT(DISTINCT message.msg_timestamp) AS average_time_between_responses\n",
    "                        FROM repo, \n",
    "                            pull_requests left outer join pull_request_message_ref \n",
    "                            on pull_requests.pull_request_id = pull_request_message_ref.pull_request_id\n",
    "                            left outer join message on pull_request_message_ref.msg_id = message.msg_id and cntrb_id not in (select cntrb_id from contributors where cntrb_login like '%[bot]')\n",
    "                        WHERE repo.repo_id = {repo_id}\n",
    "                        AND repo.repo_id = pull_requests.repo_id\n",
    "                        GROUP BY pull_requests.pull_request_id\n",
    "                ) response_times\n",
    "                ON pull_requests.pull_request_id = response_times.pull_request_id\n",
    "                left outer join (\n",
    "                        SELECT pull_requests.pull_request_id,\n",
    "                            count(*) FILTER (WHERE action = 'assigned') AS assigned_count,\n",
    "                            count(*) FILTER (WHERE action = 'review_requested') AS review_requested_count,\n",
    "                            count(*) FILTER (WHERE action = 'labeled') AS labeled_count,\n",
    "                            count(*) FILTER (WHERE action = 'unlabeled') AS unlabeled_count,\n",
    "                            count(*) FILTER (WHERE action = 'subscribed') AS subscribed_count,\n",
    "                            count(*) FILTER (WHERE action = 'mentioned') AS mentioned_count,\n",
    "                            count(*) FILTER (WHERE action = 'referenced') AS referenced_count,\n",
    "                            count(*) FILTER (WHERE action = 'closed') AS closed_count,\n",
    "                            count(*) FILTER (WHERE action = 'head_ref_force_pushed') AS head_ref_force_pushed_count,\n",
    "                            count(*) FILTER (WHERE action = 'head_ref_deleted') AS head_ref_deleted_count,\n",
    "                            count(*) FILTER (WHERE action = 'milestoned') AS milestoned_count,\n",
    "                            count(*) FILTER (WHERE action = 'merged') AS merged_count\n",
    "                        from repo, pull_requests left outer join pull_request_events \n",
    "                            on pull_requests.pull_request_id = pull_request_events.pull_request_id\n",
    "                        WHERE repo.repo_id = {repo_id}\n",
    "                            AND repo.repo_id = pull_requests.repo_id\n",
    "                        GROUP BY pull_requests.pull_request_id\n",
    "                ) event_counts on event_counts.pull_request_id = pull_requests.pull_request_id\n",
    "                LEFT OUTER JOIN (\n",
    "                        SELECT pull_request_commits.pull_request_id, count(DISTINCT pr_cmt_sha) AS commit_count                                FROM pull_request_commits, pull_requests, pull_request_meta\n",
    "                        WHERE pull_requests.pull_request_id = pull_request_commits.pull_request_id\n",
    "                        AND pull_requests.pull_request_id = pull_request_meta.pull_request_id\n",
    "                        AND pull_requests.repo_id = {repo_id}\n",
    "                        AND pr_cmt_sha <> pull_requests.pr_merge_commit_sha\n",
    "                        AND pr_cmt_sha <> pull_request_meta.pr_sha\n",
    "                        GROUP BY pull_request_commits.pull_request_id\n",
    "                ) all_commit_counts\n",
    "                ON pull_requests.pull_request_id = all_commit_counts.pull_request_id\n",
    "                LEFT OUTER JOIN (\n",
    "                        SELECT MAX(pr_repo_meta_id), pull_request_meta.pull_request_id, pr_head_or_base, pr_src_meta_label\n",
    "                        FROM pull_requests, pull_request_meta\n",
    "                        WHERE pull_requests.pull_request_id = pull_request_meta.pull_request_id\n",
    "                        AND pull_requests.repo_id = {repo_id}\n",
    "                        AND pr_head_or_base = 'base'\n",
    "                        GROUP BY pull_request_meta.pull_request_id, pr_head_or_base, pr_src_meta_label\n",
    "                ) base_labels\n",
    "                ON base_labels.pull_request_id = pull_requests.pull_request_id\n",
    "                LEFT OUTER JOIN (\n",
    "                        SELECT sum(cmt_added) AS lines_added, sum(cmt_removed) AS lines_removed, pull_request_commits.pull_request_id, count(DISTINCT cmt_filename) AS file_count\n",
    "                        FROM pull_request_commits, commits, pull_requests, pull_request_meta\n",
    "                        WHERE cmt_commit_hash = pr_cmt_sha\n",
    "                        AND pull_requests.pull_request_id = pull_request_commits.pull_request_id\n",
    "                        AND pull_requests.pull_request_id = pull_request_meta.pull_request_id\n",
    "                        AND pull_requests.repo_id = {repo_id}\n",
    "                        AND commits.repo_id = pull_requests.repo_id\n",
    "                        AND commits.cmt_commit_hash <> pull_requests.pr_merge_commit_sha\n",
    "                        AND commits.cmt_commit_hash <> pull_request_meta.pr_sha\n",
    "                        GROUP BY pull_request_commits.pull_request_id\n",
    "                ) master_merged_counts \n",
    "                ON pull_requests.pull_request_id = master_merged_counts.pull_request_id                   \n",
    "                WHERE \n",
    "                    repo.repo_group_id = repo_groups.repo_group_id \n",
    "                    AND repo.repo_id = pull_requests.repo_id \n",
    "                    AND repo.repo_id = {repo_id}\n",
    "                    AND pr_created_at >= '{begin_date}'\n",
    "                    AND pr_created_at <= '{end_date}'\n",
    "                ORDER BY\n",
    "                   merged_count DESC\n",
    "                   \"\"\")\n",
    "pr_a = pd.read_sql(pr_query, con=engine)\n",
    "if not pr_all.empty: \n",
    "    pr_all = pd.concat([pr_all, pr_a]) \n",
    "else: \n",
    "    # first repo\n",
    "    pr_all = pr_a\n",
    "\n",
    "get_repo_name_query = f\"\"\"\n",
    "    SELECT repo_name from repo where repo_id = {repo_id};\n",
    "       \"\"\"\n",
    "get_repo_name = pd.read_sql_query(get_repo_name_query, con=engine)\n",
    "repo_name = get_repo_name.repo_name[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = pd.tseries.offsets.BusinessDay(n = bus_days) \n",
    "\n",
    "pr_all['diff'] = pr_all.first_response_time - pr_all.pr_created_at\n",
    "pr_all['bus_days'] = pr_all.pr_created_at + bd\n",
    "pr_all['yearmonth'] = pr_all['pr_created_at'].dt.strftime('%Y-%m')\n",
    "\n",
    "pr_all['in_guidelines'] = np.where(pr_all['bus_days'] < pr_all['first_response_time'], 0, 1)\n",
    "\n",
    "year_month_list = pr_all.yearmonth.unique()\n",
    "year_month_list.sort()\n",
    "first_response = pr_all.groupby(['repo_name', 'yearmonth'], as_index=False).sum()[['repo_name', 'yearmonth', 'in_guidelines']]\n",
    "\n",
    "# counts total number of PRs each month\n",
    "total_by_month = pr_all.groupby(['repo_name', 'yearmonth'], as_index=False).count()[['repo_name', 'yearmonth', 'pr_created_at']]\n",
    "\n",
    "first_response['total_prs'] = total_by_month['pr_created_at']\n",
    "first_response['out_percent'] = first_response['total_prs'] - first_response['in_guidelines']\n",
    "first_response['in_percent'] = first_response['in_guidelines'] / first_response['total_prs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Whether Responses are within Business Days Threshold and Adding Analysis to Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_num = 0\n",
    "six_months = str(datetime.date.today() + relativedelta(months=-7))\n",
    "for item in first_response.iterrows():\n",
    "    year_month = item[1]['yearmonth']\n",
    "    percent = item[1]['out_percent']\n",
    "    if (percent > 0.10 and year_month >= six_months):\n",
    "        risk_num+=1\n",
    "\n",
    "title = repo_name + \"\\nTimely Responses:\"\n",
    "\n",
    "if risk_num >= bus_days:\n",
    "    title += \" AT RISK\\n\" + str(risk_num) + \" month(s) with > 10% of pull requests not responded to within \" + str(bus_days) + \" business days in the past 6 months.\"\n",
    "    title_color = 'firebrick'\n",
    "else:\n",
    "    title += \" Healthy\\nMore than 90% of pull requests responded to within \" + str(bus_days) + \" business days for \" + str(6 - risk_num) + \" out of the past 6 months.\"\n",
    "    title_color = 'forestgreen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "sns.set(style=\"whitegrid\", font_scale=2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# the size of A4 paper\n",
    "fig.set_size_inches(24, 8)\n",
    "\n",
    "bus_label = \"Response < \" + str(bus_days) + \" business days\"\n",
    "    \n",
    "plottermonth = sns.lineplot(x='yearmonth', y='total_prs', data=first_response, sort=False, color='black', label='Total', linewidth=2.5)\n",
    "plottermonth = sns.lineplot(x='yearmonth', y='in_guidelines', data=first_response, sort=False, color='green', label=bus_label, linewidth=2.5, linestyle='dashed').set_title(title, fontsize=30, color=title_color) \n",
    "\n",
    "plottermonthlabels = ax.set_xticklabels(first_response['yearmonth'], rotation=90)\n",
    "plottermonthlabels = ax.set_ylabel('Number of PRs')\n",
    "plottermonthlabels = ax.set_xlabel('Year Month\\n\\nInterpretation: Healthy projects will have little or no gap. A large or increasing gap requires attention.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional step if you would like to save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('output/bus_days.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
